{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0gyHUgj3xvzl"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Initialize Embeddings and Vector Database\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.load_local(\"faiss_index\", embedding_model)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Define a Critic Agent for Self-Evaluation\n",
        "def evaluate_response(response, retrieved_docs):\n",
        "    \"\"\"Evaluate response correctness based on retrieved docs.\"\"\"\n",
        "    evaluation_prompt = f\"\"\"\n",
        "    Given the retrieved context:\n",
        "    {retrieved_docs}\n",
        "\n",
        "    Assess the factual accuracy of the generated response:\n",
        "    {response}\n",
        "\n",
        "    If inaccurate, suggest a refined query to improve retrieval.\n",
        "    \"\"\"\n",
        "    eval_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a fact-checking AI.\"},\n",
        "                  {\"role\": \"user\", \"content\": evaluation_prompt}]\n",
        "    )\n",
        "    return eval_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# Define the Agentic Corrective RAG Process\n",
        "def agentic_corrective_rag(query):\n",
        "    \"\"\"Main pipeline for Agentic Corrective RAG.\"\"\"\n",
        "    retrieved_docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "    # First-pass response\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-4\"), retriever=retriever)\n",
        "    response = qa_chain.run(query)\n",
        "\n",
        "    # Self-evaluation and correction\n",
        "    feedback = evaluate_response(response, retrieved_docs)\n",
        "    if \"suggest\" in feedback.lower():\n",
        "        refined_query = feedback.split(\":\")[-1].strip()\n",
        "        retrieved_docs = retriever.get_relevant_documents(refined_query)\n",
        "        response = qa_chain.run(refined_query)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example Usage\n",
        "query = \"What are the latest developments in AI for medical diagnostics?\"\n",
        "corrected_response = agentic_corrective_rag(query)\n",
        "print(corrected_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjhwTjDEx2z_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}