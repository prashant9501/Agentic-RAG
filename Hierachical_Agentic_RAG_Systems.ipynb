{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVcx0HznuN9m"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Initialize LLM\n",
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "# Load FAISS as a vector store for retrieval\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "vector_store = FAISS.load_local(\"faiss_index\", embeddings=embedding_model)\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "# Step 1: High-Level Planner (Meta-Agent)\n",
        "def high_level_planner(query):\n",
        "    \"\"\"Decomposes complex queries into sub-queries.\"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are an expert in query decomposition.\"},\n",
        "                  {\"role\": \"user\", \"content\": f\"Decompose this query into sub-queries: {query}\"}]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].split(\"\\n\")\n",
        "\n",
        "# Step 2: Retrieval Agent\n",
        "def retrieve_documents(sub_queries):\n",
        "    \"\"\"Retrieves documents for each sub-query.\"\"\"\n",
        "    retrieved_docs = {}\n",
        "    for sub_query in sub_queries:\n",
        "        docs = retriever.get_relevant_documents(sub_query)\n",
        "        retrieved_docs[sub_query] = docs\n",
        "    return retrieved_docs\n",
        "\n",
        "# Step 3: Generator Agent\n",
        "def generate_responses(retrieved_docs):\n",
        "    \"\"\"Generates responses for each retrieved document set.\"\"\"\n",
        "    responses = {}\n",
        "    for sub_query, docs in retrieved_docs.items():\n",
        "        context = \"\\n\".join([doc.page_content for doc in docs])\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a domain expert.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Generate a response based on:\\n{context}\"}\n",
        "            ]\n",
        "        )\n",
        "        responses[sub_query] = response['choices'][0]['message']['content']\n",
        "    return responses\n",
        "\n",
        "# Step 4: Final Synthesis Agent\n",
        "def synthesize_final_response(sub_query_responses):\n",
        "    \"\"\"Merges multiple responses into a final coherent answer.\"\"\"\n",
        "    combined_text = \"\\n\".join(sub_query_responses.values())\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert summarizer.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Create a final answer based on:\\n{combined_text}\"}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Main Agentic RAG Function\n",
        "def hierarchical_agentic_rag(query):\n",
        "    \"\"\"Executes the full hierarchical RAG pipeline.\"\"\"\n",
        "    sub_queries = high_level_planner(query)\n",
        "    retrieved_docs = retrieve_documents(sub_queries)\n",
        "    sub_query_responses = generate_responses(retrieved_docs)\n",
        "    final_response = synthesize_final_response(sub_query_responses)\n",
        "    return final_response\n",
        "\n",
        "# Example Query\n",
        "query = \"Explain the impact of AI on healthcare and education\"\n",
        "final_output = hierarchical_agentic_rag(query)\n",
        "print(final_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r_jYDeY3uOV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}