{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install Required Libraries\n",
        "\n",
        "Run the following cell in Google Colab to install the required dependencies:"
      ],
      "metadata": {
        "id": "zLXXnODXU2Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index openai langchain"
      ],
      "metadata": {
        "id": "McIJNyNtU5uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Set Up the Environment\n",
        "You need to set your OpenAI API key for LLM predictions and embeddings. Run:"
      ],
      "metadata": {
        "id": "P-xzJm-sU7bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set your OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\""
      ],
      "metadata": {
        "id": "uqJPvu-8U9OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace \"your_openai_api_key\" with your actual OpenAI API key. If you donâ€™t have one, get it from OpenAI API Keys."
      ],
      "metadata": {
        "id": "fxMW_7sYVAu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Implement the Single-Agent Agentic RAG Router\n",
        "Now, run the following script:"
      ],
      "metadata": {
        "id": "wPph3O4gVCwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    ListIndex,\n",
        "    ServiceContext,\n",
        "    LLMPredictor,\n",
        "    OpenAIEmbedding,\n",
        "    RouterQueryEngine,\n",
        "    QueryEngineTool,\n",
        "    ResponseSynthesizer\n",
        ")\n",
        "from langchain.llms import OpenAI\n",
        "from llama_index.tools import ToolMetadata\n",
        "from llama_index.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "# Initialize the LLM predictor and service context\n",
        "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0))\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm_predictor=llm_predictor,\n",
        "    embed_model=OpenAIEmbedding()\n",
        ")\n",
        "\n",
        "# Ensure you have some documents in Google Colab\n",
        "# If needed, upload files using: from google.colab import files; files.upload()\n",
        "docs_path = \"/content/documents\"  # Update this if needed\n",
        "if not os.path.exists(docs_path):\n",
        "    os.makedirs(docs_path)\n",
        "\n",
        "# Load and index documents\n",
        "documents = SimpleDirectoryReader(docs_path).load_data()\n",
        "vector_index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "list_index = ListIndex.from_documents(documents, service_context=service_context)\n",
        "\n",
        "# Create query engines for vector and list indices\n",
        "vector_query_engine = vector_index.as_query_engine(similarity_top_k=5)\n",
        "list_query_engine = list_index.as_query_engine(response_mode=\"summary\")\n",
        "\n",
        "# Define tools for the router\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    metadata=ToolMetadata(name='vector_search', description='Perform semantic search for relevant information.')\n",
        ")\n",
        "list_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=list_query_engine,\n",
        "    metadata=ToolMetadata(name='summarizer', description='Summarize the content of the documents.')\n",
        ")\n",
        "\n",
        "# Initialize the router query engine with the defined tools\n",
        "router_query_engine = RouterQueryEngine.from_defaults(\n",
        "    selector=SubQuestionQueryEngine,\n",
        "    tools=[vector_tool, list_tool],\n",
        "    service_context=service_context,\n",
        "    response_synthesizer=ResponseSynthesizer.from_defaults()\n",
        ")\n",
        "\n",
        "# Example query\n",
        "query = \"What are the key takeaways from the latest company report?\"\n",
        "response = router_query_engine.query(query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Jdqboqp2VBCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Upload Documents (If Needed)\n",
        "If you want to upload documents manually in Google Colab, run this cell before executing the script:"
      ],
      "metadata": {
        "id": "t4qzNK_hVGF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to the `documents` directory\n",
        "import shutil\n",
        "\n",
        "docs_path = \"/content/documents\"\n",
        "if not os.path.exists(docs_path):\n",
        "    os.makedirs(docs_path)\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, os.path.join(docs_path, filename))\n",
        "\n",
        "print(f\"Uploaded {len(uploaded.keys())} files successfully!\")"
      ],
      "metadata": {
        "id": "rvKGx-HnVIFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Run the Query\n",
        "Execute the router engine query in Google Colab to see the retrieval-augmented response."
      ],
      "metadata": {
        "id": "84enh8ynVKep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Summarize the key insights from the uploaded documents.\"\n",
        "response = router_query_engine.query(query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "FPFvSKWuVKMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What This Code Does\n",
        "\n",
        "1.  Loads documents from Google Colab\n",
        "2. Builds Vector & List indices\n",
        "3. Implements a Router Query Engine\n",
        "4. Supports semantic search & summarization\n",
        "5. Queries fine-tuned RAG models\n",
        "\n"
      ],
      "metadata": {
        "id": "vaK8WUBCVOnT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jPDGRjx8VQ8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}