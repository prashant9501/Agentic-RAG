{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import os\n",
        "\n",
        "# Set API Key (Replace with your actual OpenAI key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"\n",
        "\n",
        "# Load Knowledge Base\n",
        "loader = TextLoader(\"knowledge_base.txt\")  # Replace with your file\n",
        "documents = loader.load()\n",
        "\n",
        "# Split text into manageable chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Create Vector Store for Retrieval\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vector_store = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "# Define Multi-Agent System\n",
        "\n",
        "class RetrieverAgent:\n",
        "    \"\"\"Fetches relevant documents from a vector store.\"\"\"\n",
        "    def __init__(self, vector_db):\n",
        "        self.vector_db = vector_db\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        retriever = self.vector_db.as_retriever()\n",
        "        return retriever.get_relevant_documents(query)\n",
        "\n",
        "class SummarizerAgent:\n",
        "    \"\"\"Summarizes retrieved documents for better clarity.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.llm = ChatOpenAI(model=\"gpt-4\", temperature=0.3)\n",
        "\n",
        "    def summarize(self, documents):\n",
        "        combined_text = \"\\n\".join([doc.page_content for doc in documents])\n",
        "        summary_prompt = f\"Summarize the following text:\\n{combined_text}\"\n",
        "        return self.llm.predict(summary_prompt)\n",
        "\n",
        "class EvaluatorAgent:\n",
        "    \"\"\"Evaluates the quality and relevance of retrieved documents.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.llm = ChatOpenAI(model=\"gpt-4\", temperature=0.2)\n",
        "\n",
        "    def evaluate(self, summary, query):\n",
        "        eval_prompt = f\"Evaluate if this summary properly answers '{query}':\\n{summary}\"\n",
        "        return self.llm.predict(eval_prompt)\n",
        "\n",
        "class ResponseGeneratorAgent:\n",
        "    \"\"\"Generates a final response based on evaluated information.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)\n",
        "\n",
        "    def generate_response(self, evaluated_summary):\n",
        "        response_prompt = f\"Generate a detailed response based on the following evaluated summary:\\n{evaluated_summary}\"\n",
        "        return self.llm.predict(response_prompt)\n",
        "\n",
        "# Multi-Agent System Execution\n",
        "\n",
        "class MultiAgentRAG:\n",
        "    def __init__(self, vector_db):\n",
        "        self.retriever = RetrieverAgent(vector_db)\n",
        "        self.summarizer = SummarizerAgent()\n",
        "        self.evaluator = EvaluatorAgent()\n",
        "        self.generator = ResponseGeneratorAgent()\n",
        "\n",
        "    def process_query(self, query):\n",
        "        retrieved_docs = self.retriever.retrieve(query)\n",
        "        summary = self.summarizer.summarize(retrieved_docs)\n",
        "        evaluation = self.evaluator.evaluate(summary, query)\n",
        "        final_response = self.generator.generate_response(evaluation)\n",
        "        return final_response\n",
        "\n",
        "# Instantiate Multi-Agent RAG System\n",
        "multi_agent_rag = MultiAgentRAG(vector_store)\n",
        "\n",
        "# User Query Execution\n",
        "query = \"What is the impact of AI on healthcare?\"\n",
        "response = multi_agent_rag.process_query(query)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "jPDGRjx8VQ8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}